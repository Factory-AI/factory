---
title: "Understanding Usage & Pricing"
description: "Learn how Factory measures usage, the different models available, and how to optimize your token usage for maximum efficiency"
---

## Getting Started

Factory offers different models and capabilities to support your development workflow. Understanding how usage is measured and the differences between available models will help you make the most of your Factory experience.

Usage in Factory is primarily measured through tokens, which are consumed when interacting with our AI models. Different models have different capabilities and token consumption rates.

## Available Models

Factory provides access to both standard and premium models, each optimized for different types of tasks:

<CardGroup cols={2}>
  <Card title="Standard Models" icon="robot">
    Our standard models are the most commonly used and are most economical in terms of token usage.

    **Available standard models:**

    - Claude Sonnet 3.5 v2
    - Claude Sonnet 3.7 (Low, Medium, & High Reasoning)

    Claude Sonnet 4 (Low, Medium, & High Reasoning)

    - o4-mini (Low, Medium, & High Reasoning)
    - Gemini 2.5 Pro
  </Card>
  <Card title="Premium Models" icon="crown">
    Premium models are a different expense tier. They are not necessarily better than standard models, but they are more expensive to use.

    **Available premium models:**

    - Claude Opus 4 (Low, Medium, & High Reasoning)
    - o3 (Low, Medium, & High Reasoning)
  </Card>
</CardGroup>

## Understanding Tokens

<Note>
  Tokens are the fundamental units that Factory uses to process text. Each session has a context limit based on the underlying model being used.
</Note>

### What are Tokens?

Tokens are discrete units of text that language models use to process and understand content. They represent the atomic elements of text processing, where words, subwords, or individual characters are converted into numerical values that the AI can analyze.

**Basic Concepts:**

- Tokens can be words, parts of words, or even single characters
- Common words are usually single tokens (e.g., "the", "is", "Factory")
- Longer or uncommon words might be split into multiple tokens
- Punctuation marks and spaces count as tokens

**Example Tokenization:**
The sentence "I heard a dog bark loudly" becomes:

- I
- heard
- a
- dog
- bark
- loudly

**Token Limits:**

- Maximum context window: ~120,000 tokens
- Optimal working range: 10,000-60,000 tokens
- Includes all context sources: code, documentation, conversation history

## How Usage is Measured

Factory measures usage based on the following:

<AccordionGroup>
  <Accordion title="Input Tokens">
    Input tokens are counted from:

    - Your messages to Factory
    - Context files and repositories added to your session
    - Documentation and other resources you reference
  </Accordion>
  <Accordion title="Output Tokens">
    Output tokens are generated by Factory's responses:

    - Text responses in chat
    - Generated code fragments
    - Documentation and other content created by Factory
  </Accordion>
  <Accordion title="Tool Usage">
    When using Factory Bridge or other tools:

    - Commands executed through Factory Bridge
    - API calls and integrations
    - Repository searches and file operations
  </Accordion>
</AccordionGroup>

## Usage by Plan Type

Factory offers different plans to accommodate various team sizes and usage needs:

### Free Trial

When you first sign up for Factory, you'll receive a free trial that includes:

- Limited access to premium models
- Standard context limits
- Basic integrations support

### Professional Plan

The Professional plan includes:

- Full access to all standard models
- Limited access to premium models based on your subscription
- Expanded context limits
- All integrations supported
- Priority support

### Enterprise Plan

The Enterprise plan includes:

- Unlimited access to all models including premium ones
- Maximum context limits
- Custom integrations and support
- Dedicated account management
- Advanced security features
- Custom usage quotas

## Optimizing Your Token Usage

To make the most efficient use of your tokens:

<Steps>
  <Step title="Start Focused">
    Begin with core context essential to your task:

    - Main files
    - Directly related tickets
    - Immediate documentation needs
  </Step>
  <Step title="Add Context Gradually">
    Expand context as needed:

    - Add related PRs when reviewing code
    - Include additional documentation when exploring features
    - Bring in historical context for deeper understanding
  </Step>
  <Step title="Maintain Context Hygiene">
    Regularly review and update your context:

    - Remove outdated or irrelevant information
    - Update stale documentation
    - Refresh context when switching tasks
  </Step>
  <Step title="Monitor Context Size">
    Keep an eye on your context usage:

    - Stay within the 40,000-80,000 token sweet spot
    - Use the context panel to track token usage
    - Remove unnecessary context when approaching limits
  </Step>
</Steps>

## Viewing Your Usage

You can monitor your token usage in Factory through:

1. The **Settings** page, which shows your current plan and usage statistics
2. The **Context Panel** in any session, which displays the current token count
3. Usage reports available to administrators

## Purchasing Additional Capacity

If you need additional capacity beyond your current plan:

1. Navigate to your account settings
2. Select the "Billing" tab
3. Choose the "Purchase Additional Capacity" option
4. Select the amount of additional capacity you need

<Card title="Contact Sales" icon="phone" href="mailto:sales@factory.ai">
  For custom plans or enterprise pricing, contact our sales team to discuss options tailored to your organization's needs.
</Card>

## FAQ

<AccordionGroup>
  <Accordion title="What happens when I reach my token limit?">
    When you reach your token limit, you'll receive a notification. You can:

    - Remove some context to free up tokens
    - Purchase additional capacity
    - Switch to a standard model which may use fewer tokens
  </Accordion>
  <Accordion title="Do unused tokens roll over?">
    Token usage is measured on a monthly basis for subscription plans. Unused tokens do not roll over to the next month.
  </Accordion>
  <Accordion title="Can I share tokens across my organization?">
    Enterprise plans include organization-wide token pools that can be shared among team members according to your configured policies.
  </Accordion>
  <Accordion title="How do I know which model to use?">
    Standard models are suitable for most day-to-day development tasks. Premium models are recommended for complex problem-solving, architecture design, and advanced code generation.
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Explore Context Management" icon="sitemap" href="/user-guides/managing-context/understanding-context">
    Learn more about managing context efficiently
  </Card>
  <Card title="Try Factory Bridge" icon="bridge" href="/user-guides/factory-bridge/installation-and-usage">
    Enhance your workflow with local machine integration
  </Card>
</CardGroup>