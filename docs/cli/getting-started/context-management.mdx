---
title: Context Management
description: How Factory maintains context using incremental compression and intelligent persistence
---

Factory's approach to context management enables you to work through multi-million token sessions without losing track of what you're building. Unlike other agents where context degrades or requires manual resets, Factory uses incremental compression to maintain continuity while keeping your session performant.

<CardGroup cols={2}>
  <Card title="Incremental Compression" icon="compress">
    Context grows naturally, then intelligently compresses while preserving critical information
  </Card>
  <Card title="Smart Persistence" icon="bookmark">
    Key artifacts like to-do lists, specs, and recent changes always persist across compression points
  </Card>
  <Card title="Human-Like Handoff" icon="handshake">
    Compressed context mimics how engineers hand off work - with context, errors encountered, and approaches tried
  </Card>
  <Card title="No Manual Intervention" icon="wand-magic-sparkles">
    Context management happens automatically - no need to create new chats or manually summarize
  </Card>
</CardGroup>

## How context compression works

### Why the naive approach doesn't work

The simplest approach to context management would be to re-summarize the entire conversation whenever it gets too long. This seems straightforward but fails in practice:

- **Redundant re-summarization** - Each request triggers a full re-summarization of content that was already summarized in previous turns
- **Growing cost** - The span requiring summarization grows with each turn, causing costs and latency to increase linearly with conversation length
- **Perpetual edge-of-limit** - Once compression starts, you run permanently near max context, which degrades response quality
- **Forces hierarchical summarization** - For very long conversations, you need multi-stage chunking, compounding latency and cost

Factory solves this with **incremental compression** - a fundamentally different approach.

### Factory's incremental compression approach

Rather than regenerating the entire summary per request, Factory maintains a **persistent summary** and updates it incrementally. The system uses **anchor points** - specific messages where summaries are persisted - and only summarizes newly dropped content.

**How it works:**

1. **Context grows naturally** - Your conversation and work artifacts accumulate in context
2. **Compression trigger** - When context reaches an optimal threshold, Factory compresses older messages
3. **Incremental update** - Only the newly dropped span gets summarized and merged into the existing persistent summary
4. **Anchor tracking** - Each summary is anchored to a specific message, creating a clear history of compressions

This approach delivers:

- **Model performance** - LLMs maintain attention and coherence effectively
- **Response quality** - The agent can effectively reference all context without degradation  
- **Speed** - Prompt caching remains effective and responses stay fast
- **Cost efficiency** - Only new content gets summarized, not the entire history repeatedly

<Note>
  **Key insight:** You can't rely on LLMs to correctly compress their own context. It's the agent system's responsibility to manage what information remains accessible and in what form.
</Note>

### The false economy of over-compression

Cutting context too aggressively can backfire. Once key artifacts are summarized away, the agent must re-fetch them, adding extra inference calls and latency.

In workflows that revisit the same information (like iterative code review or implementations within complex systems), these round-trips can outweigh any savings from aggressive compression.

**Factory's goal:** Minimize total work per task, not context per request. Keep just enough context to avoid repeated work while respecting the model's effective limits.

### What always persists

Certain artifacts are **never compressed** because they're essential for the agent to maintain continuity:

<AccordionGroup>
  <Accordion title="Your Specification" icon="file-lines">
    The specification created in spec mode (Shift+Tab) always remains in full form. This is your project's north star - the holistic description of what you're building, who it's for, success metrics, and potential pitfalls. The spec is treated as a living document that the agent constantly references.
  </Accordion>

  <Accordion title="To-Do List" icon="list-check">
    The current task list with status tracking persists across all compression points. This ensures the agent always knows:
    - Which tasks are completed
    - What's currently in progress
    - What's pending and in what order
    - The percentage complete of your overall work

    Without this, the agent would lose track of where it is in a multi-step implementation.
  </Accordion>

  <Accordion title="Recent Code Changes" icon="code-compare">
    Git diffs and recent file modifications remain accessible. The agent needs to know exactly what code has been changed, added, or removed during the session to avoid:
    - Re-implementing features already built
    - Breaking existing functionality
    - Losing awareness of the current state
  </Accordion>

  <Accordion title="Agent.md Files" icon="file-code">
    Your repository's agents.md files (loaded recursively from your folder structure) always stay loaded. These contain:
    - Repository-specific conventions
    - Framework-specific guidance
    - Team coding standards
    - Important context about how your codebase works

    This prevents the common issue where agents "forget" to follow your coding conventions after context resets.
  </Accordion>

  <Accordion title="Current Error State" icon="triangle-exclamation">
    Any errors, failed attempts, or blocked progress remain in context. This is critical for the agent to:
    - Not retry failed approaches
    - Remember why certain solutions didn't work
    - Continue debugging from where it left off
  </Accordion>
</AccordionGroup>

## The human handoff philosophy

Factory's compression approach is modeled on **how experienced engineers hand off work to teammates**. Rather than dumping raw conversation history, compressed context resembles a thoughtful status update:

### Example: What gets preserved

Imagine you're working on implementing OAuth authentication. After compression, the agent retains context like:

**What we're building:**
- OAuth 2.0 authentication flow with Google and GitHub providers
- User session management with JWT tokens
- Protected route middleware for the API

**Progress so far:**
- âœ… Set up OAuth credentials and environment variables
- âœ… Implemented Google OAuth callback handler
- âœ… Created user model with OAuth provider fields
- ðŸ”„ Currently implementing GitHub OAuth (in progress)
- â³ Need to add session middleware
- â³ Need to build protected route examples

**Technical context:**
- Using Express.js with Passport.js for authentication
- Database: PostgreSQL with Sequelize ORM
- Following the REST API patterns in `/api/v1/` structure
- Security: Storing tokens in httpOnly cookies, not localStorage

**Blockers and learnings:**
- Google OAuth requires verified domain (configured in console)
- Had to add `scope: ['profile', 'email']` to get user details
- The passport-github2 package works better than passport-github
- Need to handle both new user registration and existing user login cases

**Files being worked on:**
- `/routes/auth.js` - OAuth routes and callbacks
- `/models/User.js` - User model with OAuth fields
- `/middleware/auth.js` - Authentication middleware
- `/config/passport.js` - Passport strategy configuration

This is information a human engineer would provide when handing off work - and it's exactly what Factory preserves through compression.

### What gets compressed

Conversational back-and-forth, exploratory questions, and resolved issues get summarized or removed:

- âŒ "Can you explain how OAuth works?" - "Sure, OAuth is..."
- âŒ "Let me try this approach... Actually that didn't work, trying another way..."
- âŒ Resolved debugging sessions that led to the current working state
- âŒ Multiple iterations of prompt refinement
- âŒ Tangential discussions about implementation options

The key is: **decisions and outcomes stay, exploration gets compressed**.

## Best practices for extended sessions

### Start with Specification Mode

Use **Shift+Tab** to create a comprehensive spec before implementation. This becomes your persistent anchor:

```
Create a detailed specification for building a multi-tenant SaaS dashboard with:
- Organization and user management
- Role-based access control
- Billing integration with Stripe
- Real-time data updates
- Mobile responsive design

Include technical approach, success metrics, and potential challenges.
```

The spec stays in context throughout your entire session, keeping the agent aligned even after multiple compressions.

### Let the to-do list guide progress

Trust the to-do list as the source of truth. The agent maintains it automatically:

```
You: "Add user authentication to the dashboard"

Agent creates:
1. Set up auth provider configuration
2. Create login/signup UI components
3. Implement session management
4. Add protected route middleware
5. Create user profile page
```

As the agent completes each item, the list updates. After compression, it knows exactly where it left off.

### Leverage agents.md for consistency

Create `agents.md` files in your repository (especially in subdirectories) with critical context:

**Example `/backend/agents.md`:**
```markdown
# Backend Architecture

This backend uses:
- **Framework**: Express.js with TypeScript
- **Database**: PostgreSQL with Prisma ORM
- **Authentication**: JWT tokens via Passport.js
- **API Style**: RESTful with `/api/v1/` prefix

## Important Conventions

- All routes go through `/routes` with separate files per resource
- Use `/middleware` for reusable Express middleware
- Database queries use Prisma Client, never raw SQL
- All endpoints return JSON with `{ success, data, error }` structure
- Input validation via Zod schemas in `/schemas`

## Gotchas

- Prisma generates types - run `npx prisma generate` after schema changes
- JWT secret is in `.env` as JWT_SECRET
- Use `asyncHandler` wrapper for route error handling
```

This context **always stays loaded** and survives compression, ensuring consistency across the entire session.

### Save specs to files

Use `/settings` to configure spec persistence:

```
/settings
> Save spec mode: yes
```

This writes your specification to a dedicated directory as a markdown file. Benefits:

- **Version control** - Commit specs alongside code
- **Manual editing** - Update the spec file directly when requirements change
- **Reference** - The agent reads the file at the start of new sessions
- **Shareability** - Team members can read the spec to understand the work

### Monitor progress

With Factory you focus on progress:

- Is the to-do list moving forward? âœ…
- Are features working as expected? âœ…
- Is the code quality good? âœ…

If those are true, context management is working correctly throughout your entire session.

## How iterative compression evolved

Factory's compression approach went through several iterations:

<AccordionGroup>
  <Accordion title="V1: Over-engineered (didn't work well)">
    Early versions tracked multiple separate documents:
    - Accomplishments document (what's been done)
    - User intent document (what the user wants)
    - Context document (relevant information)

    This was complex to manage and led to fragmentation. The agent would get confused about which document contained what information.
  </Accordion>

  <Accordion title="V2: Naive compression (better, but not enough)">
    Simplified to: "When context grows large, compress everything into 1-2 messages."

    This worked better but had issues:
    - Lost critical details like specific errors encountered
    - To-do list would get summarized too much
    - Agent would re-explore files it had already analyzed
    - Code changes weren't always preserved accurately
  </Accordion>

  <Accordion title="V3: Selective persistence (current approach)">
    The breakthrough was realizing: **not all context is created equal**.

    Some things should **never** be compressed:
    - To-do list (always needed in full)
    - Current spec (the north star)
    - Recent code changes (what did we just do?)
    - Agent.md files (conventions and standards)
    - Active error state (what's currently broken?)

    Everything else can be compressed intelligently:
    - Conversation history â†’ summarized decisions
    - Exploratory work â†’ outcomes only
    - Resolved issues â†’ lessons learned
    - Multiple iterations â†’ final approach

    This hybrid approach delivers the best of both worlds: **comprehensive context retention with optimal performance**.
  </Accordion>
</AccordionGroup>

## Troubleshooting context issues

### Agent seems to "forget" something important

**Likely cause:** Information wasn't marked as persistent

**Solution:** Add to your agents.md or spec file:

```
/spec
[Add the forgotten context to your specification]
```

Or update `agents.md` in the relevant directory with conventions to remember.

### Agent re-explores files already analyzed

**Likely cause:** File exploration history was compressed

**Solution:** If repeatedly accessing the same files, mention them in the spec:

```
Key files being modified:
- /components/Dashboard.tsx - Main dashboard component
- /hooks/useAuth.tsx - Authentication hook
- /api/routes/user.ts - User API endpoints
```

### Agent loses track of progress

**Likely cause:** To-do list isn't being maintained

**Solution:** Explicitly ask for a to-do list:

```
Create a to-do list for this feature implementation and keep it updated as we progress.
```

The agent will maintain it across compressions.

## What information must survive compression

For Factory's synchronous chat-based coding sessions, certain information is always preserved during compression:

<CardGroup cols={2}>
  <Card title="Session Intent" icon="bullseye">
    What did you create the session for? What requirements have been stated? What is the ideal outcome?
  </Card>
  <Card title="High-Level Play-By-Play" icon="timeline">
    Major actions and decisions: "User requests refactor â†’ Assistant modifies files A, B, C â†’ User requests clarification..."
  </Card>
  <Card title="Artifact Trail" icon="code-branch">
    Which files were created, modified, or deleted? What were the key changes? Test results and their outcomes
  </Card>
  <Card title="Breadcrumbs" icon="map-signs">
    File paths, function names, and key identifiers that allow the agent to re-access truncated artifacts if needed
  </Card>
</CardGroup>

## The future: Proactive memory curation

Factory's current compression strategy is **reactive** - it compresses based on reaching context thresholds. But the future of context management is **proactive**.

### Self-directed compression

Consider an agent that just completed a complex debugging session. As soon as the error is resolved, much of the intermediate trial-and-error becomes noise for future work. Rather than waiting to hit a threshold, the agent should proactively compress completed work.

The future of Factory's context management involves:

1. **Natural breakpoints** - Agents recognize when to compress completed phases of work
2. **Structured working memory** - Maintaining persistent, structured artifacts like task lists and decision logs (already implemented)
3. **Sub-agent architectures** - Retrieval agents gather inputs, parent agents retain only final results
4. **Intelligent curation** - Agents choose what to compress based on relevance, not just age

As AI models improve at self-reflection and planning, we expect to shift from "compress when forced" to "compress when optimal."

## Summary

Factory's context management enables extended sessions through:

1. **Incremental compression** using anchor points and persistent summaries
2. **Selective persistence** of critical artifacts that never get compressed
3. **Human-like handoff** of compressed context with decisions and outcomes
4. **Smart tradeoffs** that minimize total work per task, not just context per request
5. **Zero manual intervention** required

This approach allows extended sessions while maintaining agent performance, code quality, and project continuity. You focus on building - Factory handles the context.
